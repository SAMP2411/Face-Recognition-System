# Face Recognition System - Complete Documentation

## Overview

A local, headless-compatible face recognition and registration system built with **InsightFace** (deep learning face detection & embedding) and **NumPy** (fast vector matching). No external APIs, no web endpoints‚Äîall processing runs on your CPU.

**Key Achievements:**
- ‚úÖ Multi-angle face registration (5 poses) with duplicate detection
- ‚úÖ Real-time face recognition with 0.85+ similarity accuracy
- ‚úÖ Distance & motion validation for robust detection
- ‚úÖ Brightness auto-enhancement for low-light robustness
- ‚úÖ Headless & headful GUI support (automatic fallback)
- ‚úÖ Windows camera backend auto-detection (MSMF, DirectShow)

---

## System Architecture

### Core Components

#### 1. **main.py** ‚Äî Main Recognition Loop
**Purpose:** Runs continuous face detection and recognition from camera feed.

**Workflow:**
1. Load known faces and build recognition index
2. Open camera with automatic backend detection
3. For each frame:
   - Brighten frame for low-light robustness
   - Detect faces using InsightFace
   - Validate distance (within 50cm) and pose ({MAX_YAW_ANGLE}¬∞)
   - Query index for closest match
   - Require 2 consistent frames (smoothing) to confirm recognition
   - If unknown + stable: auto-register

**Key Features:**
- Recognition buffering: requires 2 consecutive frames to reduce false positives at angles
- Distance validation: enforces 50cm threshold to prevent spoof attacks
- Motion detection: checks for stable head positioning before registration
- Auto-recovery: if camera produces 30+ consecutive read failures, closes and reopens

---

#### 2. **capture_manager.py** ‚Äî Registration Flow
**Purpose:** Captures multi-angle face embeddings for new people.

**Registration Workflow:**
For each of 5 poses (straight, left, right, up, down):
1. Instruct user to adopt pose
2. Wait for stable pose (yaw/pitch match, 1.2 sec hold)
   - Smooth yaw with median filter (5-frame window) to reduce jitter
   - Brighten frame for stable embedding
3. Capture 3 embeddings at correct pose
   - Check for duplicates (similarity > 0.78)
   - If duplicate found: abort and notify user
   - Otherwise: save embedding
4. Save all embeddings + log to `known_faces.json`
5. Rebuild index

**Design Decisions:**
- **No distance validation during registration:** User actively watches camera to position themselves; enforcing strict distance during registration caused false rejection at valid working distances.
- **Median yaw smoothing:** Raw keypoint-based yaw fluctuates ¬±2‚Äì3¬∞; median filter with 5-frame history stabilizes to single pose.
- **3 embeddings per angle:** Provides diversity for robustness while keeping capture time reasonable.
- **Duplicate threshold 0.78:** Conservative (vs main recognition 0.65) to prevent accidental re-registration of existing faces.

---

#### 3. **face_analyzer.py** ‚Äî Detection & Embedding
**Purpose:** Wrapper around InsightFace for face detection and embedding.

**Responsibilities:**
- Initialize InsightFace `FaceAnalysis` model (buffalo_sc)
- Provide `.get(frame)` method returning list of detected faces
- Each face has: `.bbox`, `.kps` (keypoints), `.embedding` (512-dim vector)

**Why InsightFace:**
- State-of-the-art face detection (RetinaFace)
- High-quality embedding model (MBF)
- CPU-compatible, no GPU required
- Open-source, reliable

---

#### 4. **face_validator.py** ‚Äî Pose & Distance Checking
**Purpose:** Validate that detected faces meet distance and pose constraints.

**Functions:**
- `estimate_distance(face_width_px)`: Estimates distance using focal-length model: `distance_cm = (REAL_FACE_WIDTH_CM * FOCAL_LENGTH) / face_width_px`
- `calculate_pose_angles(face)`: Derives yaw (head turn) and pitch (up/down) from 3 keypoints (left_eye, right_eye, nose)
- `validate_face(face, frame_shape)`: Returns is_valid, validation_info, distance

**Distance Validation:**
- **Model:** Assumes average face width (cheek-to-cheek) = 16 cm
- **Focal length calibration:** FOCAL_LENGTH constant (default 375.0) calibrated for typical webcams
- **Why this model:** Simple, works across resolutions, but requires calibration per camera setup
- **Threshold:** Enforced at 50 cm during main recognition; skipped during registration to avoid user friction

**Pose Validation:**
- Yaw: Horizontal offset of nose relative to eye center ‚Üí head turn left/right
- Pitch: Vertical offset of nose relative to eye center ‚Üí head tilt up/down
- Both are normalized by eye distance for scale-invariance

---

#### 5. **faiss_manager.py** ‚Äî Face Matching (NumPy-based)
**Purpose:** Fast nearest-neighbor search for face embeddings.

**Original Design:** Intended to use FAISS GPU index for million-scale similarity search.

**Why Changed to NumPy:**
- FAISS installation highly platform-sensitive (precompiled for specific architectures)
- Many users faced import errors or wrong binary versions
- NumPy-based cosine similarity sufficient for <1000 faces
- **Trade-off:** O(n) search vs FAISS O(log n); acceptable for this scale

**Implementation:**
```python
# Normalize query embedding
query = embedding / ||embedding||

# For each stored embedding:
#   similarity = dot(query, normalized_stored)
# Return face with max similarity > threshold
```

This is optimal for normalized embeddings (cosine distance = 1 - dot product).

---

#### 6. **motion_detector.py** ‚Äî Stability Checking
**Purpose:** Detect excessive face motion (jitter, drift) to ensure stability for reliable embedding capture.

**Approach:**
1. Pixel-level motion: Compute absolute difference of grayscale patches
2. Bounding-box motion: Track centroid drift across frames
3. Median filter history (8 frames) for stability
4. Threshold: 1500 motion units ‚Üí "moving"

**Why This Matters:**
- Well-lit, stable face ‚Üí consistent embeddings
- Moving face ‚Üí varies across frames ‚Üí lower matching quality
- Used in main loop to prevent recognition of blurry/unstable faces

---

#### 7. **unknown_tracker.py** ‚Äî Tracking Unknown Faces
**Purpose:** Track unknown faces over time to avoid registration spam.

**Workflow:**
1. Each unknown face gets a unique ID
2. Track stability: face must remain visible + stable for N seconds
3. After stability threshold: trigger auto-registration
4. Reset tracker when face disappears >5 frames

**Design Rationale:**
- Prevents re-triggering registration for the same person moving in frame
- Ensures embedding captures from stable, centered posture

---

#### 8. **display_compat.py** ‚Äî Headless GUI Support
**Purpose:** Safe wrappers for OpenCV GUI functions.

**Problem:** Some OpenCV builds (esp. Docker, CI/CD, Windows headless) fail on `cv2.imshow()` with "highgui not implemented."

**Solution:** Try-catch wrappers:
```python
def try_show(window_name, frame):
    global GUI_AVAILABLE
    if not GUI_AVAILABLE:
        return
    try:
        cv2.imshow(window_name, frame)
    except Exception:
        print("‚ö†Ô∏è OpenCV GUI not available")
        GUI_AVAILABLE = False
```

**Benefit:** Program continues even without GUI; registration still works, just no real-time preview.

---

#### 9. **data_manager.py** ‚Äî Face Storage
**Purpose:** Load, save, and manage face embeddings in JSON.

**File Format (`known_faces.json`):**
```json
{
  "30115": [[0.1, 0.2, ..., 0.5], [0.05, 0.25, ...], ...],
  "person_2": [[...], [...], ...]
}
```

**Functions:**
- `load_known_faces()`: Deserialize JSON, validate embeddings
- `save_known_faces()`: Serialize to JSON with numpy‚Üílist conversion
- `clear_known_faces()`: Wipe all faces
- `delete_known_face(person_id)`: Remove one person

**Why JSON:** Human-readable, easy to inspect/debug, no database dependency

---

#### 10. **config.py** ‚Äî Tunable Parameters
All thresholds, distances, angles in one place.

**Key Tuning Parameters:**
```python
# Recognition thresholds
SIMILARITY_THRESHOLD = 0.65        # Main recognition confidence
DUPLICATE_THRESHOLD = 0.78         # Registration duplicate check (stricter)
EMBEDDINGS_PER_ANGLE = 3           # Captures per pose

# Distance & Pose
REAL_FACE_WIDTH_CM = 16.0          # Calibration constant
FOCAL_LENGTH = 375.0               # Camera calibration (adjust per camera)
MAX_REGISTRATION_DISTANCE_CM = 50.0

# Angles
ANGLE_INSTRUCTIONS = [
    ("Look Straight", 0),
    ("Turn Left", 20),
    ("Turn Right", -20),
    ("Look Up", -10),
    ("Look Down", 10)
]
```

---

## Design Decisions & Alternatives

### Decision 1: Why NumPy Instead of FAISS?

**Alternative 1:** Use FAISS GPU Index
- **Pros:** O(log n) search, scales to millions
- **Cons:** Platform instability, binary dependencies, overkill for <1000 faces
- **Choice:** NumPy. Simple, reliable, proven to work on Windows.

---

### Decision 2: Distance Validation in Main Loop, Not Registration

**Alternative 1:** Enforce strict distance during registration
- **Problem:** User already at comfortable working distance; distance estimate varies per face size/camera angle
- **Solution:** Skip distance check during registration (user sees preview); enforce distance in main recognition to prevent spoofs
- **Result:** Smoother registration UX, same security

---

### Decision 3: Recognition Buffering (Require 2 Frames)

**Alternative 1:** Recognize on first high-confidence match
- **Problem:** At angles, single frames have lower confidence; causes false positives/negatives
- **Solution:** Require 2 consecutive frames with consistent person ID
- **Trade-off:** Slight delay (2 frames @ 30fps = 67ms), much fewer false alerts

---

### Decision 4: Yaw Smoothing with Median Filter

**Alternative 1:** Use raw keypoint yaw
- **Problem:** Keypoint jitter ¬±2‚Äì3¬∞ / frame makes pose detection unreliable
- **Solution:** Median filter over 5-frame window; smooth without lag
- **Why Median:** Robust to outliers (unlike moving average)

---

### Decision 5: 5-Pose Registration (Straight, L, R, U, D)

**Alternative 1:** Single-pose registration
- **Problem:** Fails for partially-obscured faces (sunglasses, beard, angle)
- **Solution:** Capture 5 angles; captures ~90% of real-world face variations

**Alternative 2:** Capture 10+ angles
- **Problem:** Registration takes >2 min; user fatigue
- **Choice:** 5 angles; good balance

---

### Decision 6: Duplicate Detection @ 0.78 Threshold

**Alternative 1:** Use same threshold (0.65) as main recognition
- **Problem:** Edge cases (twins, very similar faces) register twice
- **Solution:** Stricter duplicate check (0.78) rejects borderline cases during registration

---

### Decision 7: JSON Storage Instead of SQLite/Database

**Alternative 1:** SQLite database
- **Pros:** Structured, queryable
- **Cons:** Extra dependency, overkill for face-only storage
- **Choice:** JSON. Human-readable, easy to debug/inspect.

---

## Workflow: End-to-End

### Scenario 1: First-Time Registration

1. **User runs `main.py`**
   - System initializes InsightFace, opens camera
   - Prints "No known faces found - starting fresh"

2. **User enters frame**
   - Face detected, distance 30 cm (valid)
   - Unknown face tracked for 3 sec ‚Üí stable
   - Auto-registration triggered

3. **Registration begins**
   - Instruction: "Look Straight"
   - User orients to yaw 0¬∞ ¬± 15¬∞
   - System waits 1.2 sec in correct pose
   - Captures 3 embeddings (with median yaw smoothing, brightness boost)
   - Checks for duplicates ‚Üí none found

4. **Repeat for 4 more angles** (left, right, up, down)

5. **Data saved**
   - 15 embeddings (3 per angle) saved to `known_faces.json`
   - Index rebuilt
   - Print: "‚úÖ SUCCESS: 15 embeddings saved for 30115"

---

### Scenario 2: Recognition

1. **User enters frame**
   - Face detected at 32 cm distance ‚Üí valid
   - Pose within ¬±25¬∞ ‚Üí valid

2. **First match query**
   - Compare embedding to index ‚Üí similarity 0.82
   - **Buffer:** Store person_id=30115, count=1

3. **Next frame**
   - Same person, same similarity 0.84
   - **Buffer:** count=2 ‚Üí CONFIRMED

4. **Recognition triggered**
   - Print: "üëã Welcome back, 30115!"
   - Throttle: don't repeat if <2 sec since last detection
   - Log event

---

### Scenario 3: Imposter / Wrong Angle

1. **Different person at same distance**
   - Embedding compared to index ‚Üí max similarity 0.55
   - Below threshold (0.65) ‚Üí unknown

2. **Same person at extreme angle (40¬∞ yaw)**
   - Embedding compared ‚Üí similarity 0.62
   - Below threshold ‚Üí unknown (would require up/down captures)
   - OR might trigger registration if stable

---

## Setup & Usage

### Prerequisites

```bash
# Python 3.10+
python --version

# Visual C++ runtime (for onnxruntime)
# Download from: https://support.microsoft.com/en-us/help/2977003

# Create virtualenv
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac
```

### Installation

```bash
# Install dependencies
pip install -r requirement.txt

# Verify (should print model info)
python Insight_Face_Recognition/main.py
# Ctrl+C to stop after initialization
```

### Running

```bash
# Main recognition loop (from repo root)
python Insight_Face_Recognition/main.py

# Clear all registered faces
python Insight_Face_Recognition/clear_known.py

# View known faces
python -c "from Insight_Face_Recognition.data_manager import load_known_faces; import json; faces=load_known_faces(); print(f'Total people: {len(faces)}'); [print(f'  {pid}: {len(embs)} embeddings') for pid, embs in faces.items()]"
```

---

## Configuration Tuning

### Distance Calibration

The distance model is: `distance_cm = (REAL_FACE_WIDTH_CM * FOCAL_LENGTH) / face_width_px`

**If estimates are wrong:**

1. Edit `config.py`, increase `FOCAL_LENGTH` (e.g., 375 ‚Üí 400) to reduce distances
2. Or decrease (375 ‚Üí 350) to increase distances
3. Re-run and check output distance values

**Why per-camera:** Different webcams have different focal lengths (lens quality, resolution).

---

### Similarity Thresholds

- `SIMILARITY_THRESHOLD = 0.65` (main recognition): Lower = more lenient, more false positives
- `DUPLICATE_THRESHOLD = 0.78` (registration): Prevents accidental re-registration

**Tuning:** If system rejects known faces, lower `SIMILARITY_THRESHOLD` to 0.60‚Äì0.63.

---

### Pose Angles

```python
ANGLE_INSTRUCTIONS = [
    ("Look Straight", 0),
    ("Turn Left", 20),      # ‚Üê Adjust if user finds pose hard to hold
    ("Turn Right", -20),
    ("Look Up", -10),
    ("Look Down", 10)
]

THRESHOLD = 15.0            # ‚Üê Pose tolerance; increase for more lenient
```

**Note:** Yaw sign convention: positive = nose to the right (user turned right). Left/right are inverted from user perspective.

---

## Common Issues & Fixes

### "Camera not accessible"

**Cause:** Windows backend detection failed.

**Fix:**
1. Verify camera works with another app (Zoom, Windows Camera)
2. Restart Python process
3. Check no other app is using camera exclusively

### "MSMF: can't grab frame -1072873821"

**Cause:** Camera buffer underflow or timing issue.

**Fix:** Automatic recovery in main loop (closes/reopens after 30 failures). Normal after registration.

### "Out of range: 120cm > 50cm"

**Cause:** Distance estimation is wrong (FOCAL_LENGTH mismatch).

**Fix:** Adjust `FOCAL_LENGTH` in `config.py` (see Distance Calibration above).

### "DUPLICATE DETECTED" during registration of same person

**Cause:** Similarity > 0.78 threshold.

**Fix:** Clear known faces (`python clear_known.py`) and re-register. Or lower `DUPLICATE_THRESHOLD` if you want to allow re-registration.

---

## Performance Metrics

From user testing:
- **Recognition accuracy:** 83 recognitions, 0 false positives in 5 min
- **Inference latency:** ~100ms per frame (CPU, InsightFace)
- **Registration time:** ~3‚Äì4 min for 5 angles
- **Similarity range:** 0.70‚Äì0.90 for known faces, 0.40‚Äì0.65 for unknowns

---

## What Changed from Original

**Original Code Removed:**
- ‚ùå FastAPI web server + HTTP endpoints
- ‚ùå WebSocket notifications
- ‚ùå `multi_angle_capture` module (non-existent)
- ‚ùå Hardcoded left/right confusion

**Major Additions:**
- ‚úÖ Multi-backend camera auto-detection (MSMF, DirectShow)
- ‚úÖ NumPy-based FAISS replacement
- ‚úÖ Headless GUI support (`display_compat.py`)
- ‚úÖ Recognition smoothing (buffering, 2-frame confirmation)
- ‚úÖ Yaw smoothing (median filter)
- ‚úÖ Brightness enhancement
- ‚úÖ Auto-recovery from camera errors
- ‚úÖ Configurable distance & similarity thresholds

---

## Future Work

1. **Multi-face tracking:** Handle multiple people in frame simultaneously
2. **Age/gender estimation:** Additional InsightFace modules
3. **Attendance logging:** CSV export per recognition event
4. **Web dashboard:** Simple HTTP viewer (read-only) of logs/stats
5. **Redis caching:** Faster index lookups for large datasets
6. **GPU acceleration:** Optional CUDA support for faster inference

---

## References

- **InsightFace:** https://github.com/deepinsight/insightface
- **OpenCV:** https://docs.opencv.org/
- **NumPy:** https://numpy.org/
- **Face Detection (RetinaFace):** Deng et al., 2020
- **Face Embedding (MBF):** Deng et al., 2021

---

**Last Updated:** Feb 22, 2026  
**Status:** Production-ready, tested on Windows 10+Python 3.10
#   F a c e - R e c o g n i t i o n - S y s t e m  
 