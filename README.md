# Face Recognition System - Complete Documentation

A **local, production-ready** face recognition and registration system built with **InsightFace** (deep learning face detection & embedding) and **NumPy** (fast vector matching). No external APIs, no web endpoints‚Äîall processing runs on your CPU.

---

## Key Achievements

- ‚úÖ **Multi-angle face registration** (5 poses: straight, left, right, up, down) with duplicate detection
- ‚úÖ **Real-time face recognition** with 85%+ similarity accuracy (0 false positives in testing)
- ‚úÖ **Distance & motion validation** for robust detection (prevents spoofs, ensures stability)
- ‚úÖ **Brightness auto-enhancement** for low-light robustness
- ‚úÖ **Headless & GUI support** (automatic fallback for Docker/headless environments)
- ‚úÖ **Windows camera backend auto-detection** (MSMF, DirectShow, auto-recovery)
- ‚úÖ **Recognition smoothing** (2-frame buffering reduces angle-based false positives)
- ‚úÖ **Yaw smoothing** (median filter stabilizes pose detection)
- ‚úÖ **Modular, well-documented architecture** with clear design rationale

---

## Tech Stack

- **Python 3.10+** (recommended)
- **InsightFace 0.7.3** ‚Äî Face detection (RetinaFace) & embedding (MBF) models
- **ONNX Runtime** (CPU provider; optional GPU provider for NVIDIA cards)
- **NumPy** ‚Äî Cosine similarity search (replaced FAISS for platform stability)
- **OpenCV 4.12** ‚Äî Camera I/O and display (with headless fallback)
- **SciPy** ‚Äî Focal-length distance estimation
- **Tqdm** ‚Äî Progress bars during registration

---

## System Architecture

### 10 Core Components

#### 1. **main.py** ‚Äî Main Recognition Loop
**Purpose:** Continuous face detection, validation, and recognition from live camera feed.

**Workflow:**
1. Load known faces from JSON and build recognition index
2. Open camera with automatic backend detection (MSMF ‚Üí DirectShow ‚Üí auto)
3. For each frame:
   - Brighten frame (alpha=1.08, beta=18) for low-light robustness
   - Detect faces using InsightFace RetinaFace
   - Validate distance (‚â§50 cm) and pose (¬±25¬∞ yaw/pitch)
   - Query index for closest match
   - **Buffer recognition:** Require 2 consecutive frames with same person ID (reduces false positives at angles)
   - If unknown + stable (3+ sec): trigger auto-registration

**Key Features:**
- **Recognition buffering:** Smooths single-frame jitter by averaging 2 frames
- **Distance validation:** Enforces 50 cm threshold to prevent spoofs at extreme distances
- **Motion tracking:** Unknown faces tracked via `UnknownFaceTracker`; triggers registration only after stability
- **Auto-recovery:** If camera produces 30+ consecutive read failures, closes and reopens device
- **Throttling:** Prevents duplicate notifications (min 2 sec between same-person alerts)

---

#### 2. **capture_manager.py** ‚Äî Multi-Angle Registration
**Purpose:** Captures diverse face embeddings across 5 poses for robust recognition.

**Registration Workflow (per angle):**
1. Instruct user: "Look Straight" / "Turn Left" / etc.
2. Wait for stable pose:
   - Brighten frame (alpha=1.15, beta=25) for stable embedding
   - Compute yaw/pitch from keypoints
   - **Smooth yaw** with median filter (5-frame window) to reduce jitter
   - Hold pose for 1.2 sec minimum (prevents accidental captures)
3. Capture 3 embeddings at correct pose angle:
   - Check for duplicates (similarity > 0.78) against known faces
   - If duplicate found ‚Üí abort, notify user
   - Otherwise ‚Üí save embedding to list
4. Repeat for 5 poses (straight, L, R, up, down) ‚Üí 15 total embeddings
5. Save to `known_faces.json`, rebuild index

**Design Decisions:**
- **No distance validation during registration:** User actively watches camera preview; strict distance caused false rejections at comfortable working distances
- **Median yaw smoothing:** Raw keypoint yaw fluctuates ¬±2‚Äì3¬∞/frame; median filter stabilizes without lag
- **3 embeddings per angle:** Balance between diversity (robustness) and capture time (~3‚Äì4 min total)
- **Duplicate threshold 0.78:** Stricter than main recognition (0.65) to prevent accidental re-registration of twins/similar faces

---

#### 3. **face_analyzer.py** ‚Äî Detection & Embedding
**Purpose:** Wrapper around InsightFace models for face detection and 512-dim embedding extraction.

**Models Used:**
- **Detection:** RetinaFace (buffalo_sc) ‚Äî multi-scale, robust to small faces, occlusion
- **Embedding:** MBF (Margin-based Feature, buffalo_sc) ‚Äî 512-dim vector, optimized for face verification

**Responsibilities:**
- Initialize InsightFace `FaceAnalysis` with CPU provider
- Provide `.get(frame)` method returning list of detected faces
- Each face object contains: `.bbox` (bounding box), `.kps` (5 keypoints: L-eye, R-eye, nose, L-mouth, R-mouth), `.embedding` (normalized 512-dim vector)

**Why InsightFace:**
- State-of-the-art accuracy for face detection/embedding
- Efficient inference on CPU (~100ms/frame)
- Open-source, actively maintained
- Pre-trained models included

---

#### 4. **face_validator.py** ‚Äî Pose & Distance Checking
**Purpose:** Validate detected faces meet distance and pose constraints for safe recognition.

**Key Functions:**
- `estimate_distance(face_width_px)`: Uses focal-length model: `distance_cm = (REAL_FACE_WIDTH_CM * FOCAL_LENGTH) / face_width_px`
- `calculate_pose_angles(face)`: Derives yaw and pitch from 3 keypoints (left_eye, right_eye, nose)
- `validate_face(face, frame_shape)`: Returns (is_valid, validation_info, distance)

**Distance Model:**
- Assumes average face width (cheek-to-cheek) = 16 cm
- Focal length (default 375.0) is camera-specific; adjust per setup
- Why this approach: Simple, works across resolutions, but requires per-camera calibration

**Pose Calculation:**
- **Yaw (left/right turn):** Horizontal offset of nose relative to eye center
  - Positive yaw = nose to the right (user turned right)
  - Normalized by inter-eye distance for scale-invariance
- **Pitch (up/down tilt):** Vertical offset of nose relative to eye center
  - Negative = looking up, positive = looking down
  - Also normalized by eye distance

**Recognition Thresholds:**
- Main loop: Enforces 50 cm (prevents spoofs from distance)
- Registration: Skipped (user sees preview; allows flexible working distance)

---

#### 5. **faiss_manager.py** ‚Äî Face Matching (NumPy-Based)
**Purpose:** Fast nearest-neighbor search for face embeddings.

**Original Design:** Intended FAISS GPU index for million-scale similarity search.

**Why Changed to NumPy:**
- **Problem with FAISS:** Platform-sensitive binary dependencies, frequent import errors on Windows
- **Solution:** NumPy-based cosine similarity, sufficient for <1000 faces
- **Trade-off:** O(n) search vs FAISS O(log n), but acceptable for this scale

**Implementation:**
```python
# Normalize query embedding
query = embedding / ||embedding||

# For each stored embedding:
#   similarity = dot(query, normalized_stored)  # cosine similarity

# Return person_id with max similarity > threshold
```

Optimal for normalized embeddings (cosine distance = 1 - dot product).

---

#### 6. **motion_detector.py** ‚Äî Stability Checking
**Purpose:** Detect excessive face motion (jitter, drift) to ensure stable embedding capture.

**Approach:**
1. **Pixel-level motion:** Absolute difference of grayscale patches between frames
2. **Bounding-box motion:** Track centroid drift (L2 distance)
3. **History filter:** Median of 8-frame motion window (robust to outliers)
4. **Threshold:** 1500 motion units ‚Üí "moving" state

**Why This Matters:**
- Blur/motion reduces embedding quality ‚Üí lower matching confidence
- Used in main loop to suppress recognition during rapid head movement
- Ensures registration captures are from stable, sharp frames

---

#### 7. **unknown_tracker.py** ‚Äî Unknown Face Tracking
**Purpose:** Track unknown faces over time; trigger registration only after stability.

**Workflow:**
1. Each unknown face gets unique tracking ID
2. Faces tracked for consecutive frames
3. After 3+ seconds of visible + stable face ‚Üí trigger registration
4. Reset tracker when face disappears >5 frames

**Design Rationale:**
- Prevents registration spam (same person moving in frame)
- Ensures embeddings captured from centered, stable posture
- Resets on absence to allow re-registration of new people

---

#### 8. **display_compat.py** ‚Äî Headless GUI Support
**Purpose:** Safe wrappers for OpenCV GUI functions to support headless environments.

**Problem:** Some OpenCV builds (Docker, CI/CD, headless Windows) fail on `cv2.imshow()` with "highgui not implemented."

**Solution:** Try-catch wrappers:
```python
def try_show(window_name, frame):
    global GUI_AVAILABLE
    if not GUI_AVAILABLE:
        return
    try:
        cv2.imshow(window_name, frame)
    except Exception as e:
        print(f"‚ö†Ô∏è OpenCV GUI not available")
        GUI_AVAILABLE = False
```

**Benefit:** Program continues without GUI; registration still works, just no real-time preview.

---

#### 9. **data_manager.py** ‚Äî Face Data Storage
**Purpose:** Load, save, and manage face embeddings in JSON format.

**File Format (`known_faces.json`):**
```json
{
  "30115": [[0.1, 0.2, ..., 0.5], [0.05, 0.25, ...], ...],
  "person_2": [[...], [...], ...]
}
```

**Functions:**
- `load_known_faces()` ‚Äî Deserialize JSON, validate embeddings
- `save_known_faces(data)` ‚Äî Serialize to JSON with numpy‚Üílist conversion
- `clear_known_faces()` ‚Äî Wipe all registered faces
- `delete_known_face(person_id)` ‚Äî Remove one person

**Why JSON:** Human-readable, easy to inspect/debug, no database dependency, portable

---

#### 10. **config.py** ‚Äî Tunable Parameters
All thresholds, distances, angles in one configuration file.

**Key Parameters:**
```python
# Recognition
SIMILARITY_THRESHOLD = 0.65        # Main recognition confidence
DUPLICATE_THRESHOLD = 0.78         # Registration (stricter)
EMBEDDINGS_PER_ANGLE = 3           # Captures per pose

# Distance & Pose
REAL_FACE_WIDTH_CM = 16.0          # Face width assumption
FOCAL_LENGTH = 375.0               # Camera focal length (adjust per camera)
MAX_REGISTRATION_DISTANCE_CM = 50.0

# Motion & Stability
MOTION_THRESHOLD = 1500            # Motion detection threshold
STABILITY_TIME = 1.0               # Hold time for pose (seconds)

# Angles (yaw convention: positive = nose right)
ANGLE_INSTRUCTIONS = [
    ("Look Straight", 0),
    ("Turn Left", 20),      # Inverted: user left = +yaw
    ("Turn Right", -20),
    ("Look Up", -10),
    ("Look Down", 10)
]

THRESHOLD = 15.0                   # Pose tolerance (degrees)
```

---

## Design Decisions & Alternatives Explored

### Decision 1: NumPy Instead of FAISS

**Alternative:** Use FAISS GPU Index
- **Pros:** O(log n) search, million-scale, proven at scale
- **Cons:** Platform instability, binary dependencies, overkill for <1000 faces
- **Chosen:** NumPy. Simple, reliable, proven on Windows, sufficient for this scale

---

### Decision 2: Skip Distance Validation During Registration

**Alternative:** Enforce strict distance during registration
- **Problem:** User at comfortable working distance (20‚Äì40 cm); distance estimate varies per face size/angle
- **Result:** False rejections frustrate users during registration
- **Chosen:** Skip distance during registration (user sees preview), enforce in main loop for spoof prevention
- **Outcome:** Smoother UX, same security

---

### Decision 3: Recognition Buffering (2-Frame Confirmation)

**Alternative:** Recognize on first high-confidence match
- **Problem:** At angles, single frames lower confidence; causes false positives/negatives
- **Solution:** Require 2 consecutive frames with consistent person ID
- **Trade-off:** Slight delay (2 frames @ 30fps = 67ms), much fewer false alerts
- **Chosen:** 2-frame buffering; users don't notice 67ms delay

---

### Decision 4: Yaw Smoothing with Median Filter

**Alternative:** Use raw keypoint yaw
- **Problem:** Keypoint jitter ¬±2‚Äì3¬∞/frame makes pose detection unreliable
- **Solution:** Median filter over 5-frame window; smooth without lag
- **Why Median:** Robust to outliers (unlike moving average)
- **Chosen:** Median filter; stable pose detection without hysteresis

---

### Decision 5: 5-Pose Registration (Straight, L, R, U, D)

**Alternative 1:** Single-pose registration
- **Problem:** Fails for partially-obscured faces (sunglasses, beard, angle)

**Alternative 2:** Capture 10+ angles
- **Problem:** Registration takes >2 min; user fatigue

**Chosen:** 5 poses. ~90% real-world coverage, ~3‚Äì4 min total time, good balance

---

### Decision 6: Stricter Duplicate Detection (0.78 vs 0.65)

**Alternative:** Use same threshold (0.65) as main recognition
- **Problem:** Edge cases (twins, very similar faces) re-register accidentally
- **Chosen:** 0.78 for registration (stricter); prevents false duplicates during registration

---

### Decision 7: JSON Storage vs. SQLite

**Alternative:** SQLite database
- **Pros:** Structured, queryable
- **Cons:** Extra dependency, overkill for face-only storage
- **Chosen:** JSON. Human-readable, easy to debug/inspect, portable

---

## End-to-End Workflows

### Workflow 1: First-Time Registration

1. **User runs `main.py`**
   - System initializes InsightFace (downloads models if needed)
   - Opens camera
   - Prints "No known faces found - starting fresh"

2. **User enters frame**
   - Face detected at 30 cm ‚Üí valid distance
   - Unknown face tracked for 3 sec ‚Üí stable

3. **Auto-registration triggered**
   - Instruction: "Look Straight"
   - User orients to yaw 0¬∞ ¬± 15¬∞
   - System waits 1.2 sec in correct pose (with median smoothing)
   - Captures 3 embeddings (brightness boosted to 1.15)
   - Checks for duplicates ‚Üí none found

4. **Repeat for 4 more angles** (left, right, up, down)

5. **Data saved**
   - 15 embeddings (3 per 5 angles) saved to `known_faces.json`
   - Index rebuilt
   - Print: "‚úÖ SUCCESS: 15 embeddings saved for 30115"

---

### Workflow 2: Face Recognition

1. **User enters frame**
   - Face detected at 32 cm distance ‚Üí valid
   - Pose within ¬±25¬∞ ‚Üí valid

2. **Frame 1: First match query**
   - Compare embedding to index ‚Üí similarity 0.82
   - Store in buffer: person_id="30115", count=1

3. **Frame 2: Confirm**
   - Same person, similarity 0.84
   - Buffer count=2 ‚Üí **CONFIRMED**
   - Reset buffer

4. **Recognition triggered**
   - Print: "üëã Welcome back, 30115!"
   - Throttle: don't repeat if <2 sec since last alert
   - Log event to `face_recognition_log.json`

---

### Workflow 3: Spoofing Attempt / Wrong Angle

1. **Different person at same distance**
   - Embedding compared to index ‚Üí max similarity 0.55
   - Below threshold (0.65) ‚Üí treat as unknown

2. **Same person at extreme angle (40¬∞ yaw)**
   - Embedding compared ‚Üí similarity 0.62
   - Below threshold ‚Üí unknown (would need left/right captures)
   - OR: triggers registration if stable (adds depth to index)

---

## Setup & Usage

### Prerequisites

```bash
# Python 3.10+ (64-bit)
python --version

# Visual C++ runtime (for onnxruntime)
# Windows: Download from https://support.microsoft.com/en-us/help/2977003

# Create virtualenv
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac
```

### Installation

```bash
# Install dependencies
pip install -r requirement.txt

# Verify setup
python Insight_Face_Recognition/main.py
# Press Ctrl+C after model initialization
```

### Running

```bash
# Main recognition loop
python Insight_Face_Recognition/main.py

# Clear all registered faces
python Insight_Face_Recognition/clear_known.py

# View registered people
python -c "from Insight_Face_Recognition.data_manager import load_known_faces; faces=load_known_faces(); print(f'Total: {len(faces)}'); [print(f'  {pid}: {len(embs)} embeddings') for pid, embs in faces.items()]"
```

---

## Configuration Tuning

### Distance Calibration

**Formula:** `distance_cm = (REAL_FACE_WIDTH_CM * FOCAL_LENGTH) / face_width_px`

**If estimates are wrong:**
1. Edit `config.py`, adjust `FOCAL_LENGTH`:
   - Increase (e.g., 375 ‚Üí 400) to reduce estimated distances
   - Decrease (e.g., 375 ‚Üí 350) to increase estimated distances
2. Run and check output distances
3. Iterate until estimates match reality

**Why per-camera:** Different webcams have different focal lengths.

---

### Similarity Thresholds

- `SIMILARITY_THRESHOLD = 0.65` (main recognition): Lower = more lenient, higher false-positive rate
- `DUPLICATE_THRESHOLD = 0.78` (registration): Prevents accidental re-registration

**Tuning:** If system rejects known faces at certain angles, lower `SIMILARITY_THRESHOLD` to 0.60‚Äì0.63.

---

### Pose Angles

```python
ANGLE_INSTRUCTIONS = [
    ("Look Straight", 0),
    ("Turn Left", 20),      # Adjust if user finds pose hard to hold
    ("Turn Right", -20),
    ("Look Up", -10),
    ("Look Down", 10)
]

THRESHOLD = 15.0            # Pose tolerance; increase for more lenient
```

**Note:** Yaw convention: positive = nose to the right. From user perspective, left/right are inverted.

---

## Common Issues & Solutions

### "Camera not accessible"
**Cause:** Windows backend detection failed.
```bash
# Fix: Verify camera works with Zoom, Windows Camera, etc.
# Restart Python process
# Ensure no other app is using camera exclusively
```

### "MSMF: can't grab frame -1072873821"
**Cause:** Camera buffer underflow after registration.
**Fix:** Automatic recovery in main loop (closes/reopens after 30 failures).

### "Out of range: 120cm > 50cm"
**Cause:** Distance estimation mismatch (wrong FOCAL_LENGTH).
**Fix:** Adjust `FOCAL_LENGTH` in `config.py` (see Distance Calibration above).

### "DUPLICATE DETECTED" during re-registration
**Cause:** Similarity > 0.78.
**Fix:** Run `python clear_known.py` and re-register, or lower `DUPLICATE_THRESHOLD`.

---

## Performance Metrics

From user testing:
- **Recognition accuracy:** 83 recognitions, 0 false positives in 5 min
- **Inference latency:** ~100ms per frame (CPU, InsightFace)
- **Registration time:** ~3‚Äì4 min for 5 angles
- **Similarity range:** 0.70‚Äì0.90 for known faces, 0.40‚Äì0.65 for unknowns

---

## What Changed from Original

**Removed (API/Web):**
- ‚ùå FastAPI web server + HTTP endpoints
- ‚ùå WebSocket notifications
- ‚ùå `multi_angle_capture` module (non-existent)
- ‚ùå Hardcoded left/right confusion

**Major Improvements:**
- ‚úÖ Multi-backend camera auto-detection (MSMF, DirectShow, fallback)
- ‚úÖ NumPy-based FAISS replacement (stability, simplicity)
- ‚úÖ Headless GUI support (`display_compat.py`)
- ‚úÖ Recognition smoothing (2-frame buffering, median yaw filter)
- ‚úÖ Brightness enhancement (low-light robustness)
- ‚úÖ Auto-recovery from camera errors (30-failure threshold)
- ‚úÖ Configurable distance/similarity thresholds
- ‚úÖ Complete documentation of design rationale

---

## Future Enhancements

1. **Multi-face tracking** ‚Äî Handle multiple people in frame simultaneously
2. **Age/gender estimation** ‚Äî Additional InsightFace modules
3. **Attendance logging** ‚Äî CSV export per recognition event
4. **Web dashboard** ‚Äî Simple HTTP viewer (read-only) of logs/stats
5. **Redis caching** ‚Äî Faster index lookups for large datasets
6. **GPU acceleration** ‚Äî Optional CUDA support for faster inference
7. **Mask detection** ‚Äî Handle faces with occlusion

---

## References

- **InsightFace:** https://github.com/deepinsight/insightface
- **RetinaFace:** Deng et al., 2020
- **MBF Embeddings:** Deng et al., 2021
- **OpenCV:** https://docs.opencv.org/
- **NumPy:** https://numpy.org/

---

## Author & License

**Author:** Samarth Patel  
M.Sc. Automation & Robotics, TU Dortmund

**License:** MIT

**Last Updated:** Feb 22, 2026  
**Status:** Production-ready, tested on Windows 10, Python 3.10

